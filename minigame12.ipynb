{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minigame 12: Patched Evaluation\n",
    "\n",
    "In this exploration, we're looking at the ability to take policies trained on small patches and to apply them to larger meshes by combining the logits/distributions/q-values from each of the NN evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sin,cos\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces, utils\n",
    "import numpy as np\n",
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "import ray.rllib.agents.dqn as dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glvis import glvis, to_stream\n",
    "from ipywidgets import Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mfem import path\n",
    "import mfem.ser as mfem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some synthetic test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(x,theta):\n",
    "    x0 = x[0]\n",
    "    y0 = x[1]\n",
    "    x1 = x0*cos(theta)-y0*sin(theta)\n",
    "    y1 = x0*sin(theta)+y0*cos(theta)\n",
    "    return [x1,y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bump(x):\n",
    "    rsq = x[0]**2 +x[1]**2\n",
    "    return math.exp(-rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_step(x):\n",
    "    return 0.5*(1.0 +math.tanh(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotated_smooth_step(x,theta):\n",
    "    xr = rotate(x,theta)\n",
    "    return smooth_step(xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create classes where we can set the parameters and then eval a bunch of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.theta = random.uniform(0.0, 2.0*math.pi)\n",
    "        self.dx = [random.uniform(-1.0, 1.0),random.uniform(-1.0, 1.0)]\n",
    "        \n",
    "    def EvalValue(self, x):\n",
    "        return rotated_step(x+self.dx, self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bump(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.width = random.uniform(0.05,0.1)\n",
    "        self.xc = [0.5,0.5]\n",
    "        self.dx = [random.uniform(-0.5, 0.5),random.uniform(-0.5, 0.5)]\n",
    "\n",
    "    def EvalValue(self, x):\n",
    "        return bump((x-self.xc+self.dx)/self.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothStep(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.width = random.uniform(5.0, 15.0)\n",
    "        self.xc = [0.5,0.5]\n",
    "        self.dx = random.uniform(-0.5,0.5)\n",
    "        self.theta = random.uniform(0.0, 2.0*math.pi)\n",
    "\n",
    "    def EvalValue(self, x):\n",
    "        x -= self.xc\n",
    "        x += self.dx\n",
    "        return rotated_smooth_step(x*self.width, self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BumpAndSmoothStep(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.bump = Bump()\n",
    "        self.bump.SetParams()\n",
    "        self.smooth_step = SmoothStep()\n",
    "        self.smooth_step.SetParams()\n",
    "\n",
    "    def EvalValue(self, x):\n",
    "        return 0.5*self.bump.EvalValue(x)+0.5*self.smooth_step.EvalValue(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize an instance of the test function. Note that each instance has randomly chosen parameters.  For the steps, it's a rotation angle and a displacement.  For the bumps, it's a width and a displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = mfem.Mesh('inline-quad.mesh')\n",
    "mesh.UniformRefinement()\n",
    "mesh.UniformRefinement()\n",
    "fec = mfem.L2_FECollection(p=1, dim=2)\n",
    "fes = mfem.FiniteElementSpace(mesh, fec)\n",
    "u = mfem.GridFunction(fes)\n",
    "c = Bump()\n",
    "c.SetParams()\n",
    "u.ProjectCoefficient(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4517dfd6ec3c49fca449689b7c4587a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "glvis()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glvis(to_stream(mesh,u) + 'keys Rcjm', 500, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the gym environment. Note that in this case, this can be just a dummy environment that only serves to define the observation and action spaces for the purposes of evaluation of the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRGameDummy(gym.Env):\n",
    "        \n",
    "    # In RLlib, you need the config arg\n",
    "    def __init__(self,config):\n",
    "        self.meshfile = 'inline-quad-5.mesh'\n",
    "        self.mesh = mfem.Mesh(self.meshfile)\n",
    "        \n",
    "        # The only reason we need to create a fespace and gf here\n",
    "        # is to find the sizes needed for the action and observation spaces\n",
    "        dim = self.mesh.Dimension()\n",
    "        self.order = 1\n",
    "        self.fec = mfem.L2_FECollection(self.order, dim)\n",
    "        self.fes = mfem.FiniteElementSpace(self.mesh, self.fec)\n",
    "        self.u = mfem.GridFunction(self.fes);\n",
    "\n",
    "        # actions are: refine each element, or do nothing\n",
    "        self.action_space = spaces.Discrete(self.mesh.GetNE())\n",
    "        \n",
    "        # observation space: DOFs\n",
    "        self.observation_space = spaces.Box(-1.0, 1.0, shape=(self.u.Size(),), dtype=np.float32)\n",
    "        \n",
    "    def step(self, action):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator game has a different action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorGameDummy(gym.Env):\n",
    "    \n",
    "    class u0_coeff(mfem.PyCoefficient):\n",
    "        \n",
    "        def SetParams(self):\n",
    "            #self.fn = BumpAndSmoothStep()\n",
    "            self.fn = Bump()\n",
    "\n",
    "            self.fn.SetParams()\n",
    "            \n",
    "        def Print(self):\n",
    "            self.fn.Print()\n",
    "            \n",
    "        def EvalValue(self, x):\n",
    "            v = self.fn.EvalValue(x)\n",
    "            #assert v >= 0.0\n",
    "            #assert v <= 1.0\n",
    "            return self.fn.EvalValue(x)\n",
    "    \n",
    "    # precompute the observation points and the elements and integration points we need\n",
    "    def get_obs_points(self):\n",
    "        n = math.sqrt(self.mesh.GetNE())\n",
    "        dx = 1.0/self.obsx\n",
    "        dy = 1.0/self.obsy\n",
    "        self.sample_pts = []\n",
    "        self.sample_els = []\n",
    "        self.sample_ips = []\n",
    "        for j in range(self.obsy):\n",
    "            for i in range(self.obsx):\n",
    "                pt = [i*dx+0.5*dx,j*dy+0.5*dy]\n",
    "                self.sample_pts.append(pt)\n",
    "                n, el, ip = self.mesh.FindPoints([pt])\n",
    "                #assert n == 1\n",
    "                #assert ip[0].x > 0.0\n",
    "                #assert ip[0].x < 1.0\n",
    "                #assert ip[0].y > 0.0\n",
    "                #assert ip[0].y < 1.0\n",
    "                #assert el[0] >= 0\n",
    "                #assert el[0] < self.mesh.GetNE()\n",
    "                # copy these so they won't be destroyed when mesh goes away?\n",
    "                ip0 = mfem.IntegrationPoint()\n",
    "                ip0.x = ip[0].x\n",
    "                ip0.y = ip[0].y\n",
    "                self.sample_els.append(el[0])\n",
    "                self.sample_ips.append(ip0)\n",
    "                \n",
    "    def get_obs(self):\n",
    "        state = np.empty((self.obsx,self.obsy,1))\n",
    "        k = 0\n",
    "        for j in range(self.obsy):\n",
    "            for i in range(self.obsx):\n",
    "                #assert k < len(self.sample_els)\n",
    "                #assert k < len(self.sample_ips)\n",
    "                el = self.sample_els[k]\n",
    "                #assert el >= 0\n",
    "                #assert el < self.mesh.GetNE()\n",
    "                ip = self.sample_ips[k]\n",
    "                #assert ip.x >= 0.0, \"k={}, i={}, j={}, x is {}\".format(k,i,j,ip.x)\n",
    "                #assert ip.x <= 1.0, \"k={}, i={}, j={}, x is {}\".format(k,i,j,ip.x)\n",
    "                #assert ip.y >= 0.0, \"k={}, i={}, j={}, y is {}\".format(k,i,j,ip.y)\n",
    "                #assert ip.y <= 1.0, \"k={}, i={}, j={}, y is {}\".format(k,i,j,ip.y)\n",
    "                v = self.u.GetValue(self.sample_els[k],self.sample_ips[k])\n",
    "                state[i][j] = v\n",
    "                if (v > 2.0 or v < -1.0):\n",
    "                    print(\"element %d\" % self.sample_els[k])\n",
    "                    print(\"ip.x = %f\" % self.sample_ips[k].x)\n",
    "                    print(\"ip.y = %f\" % self.sample_ips[k].y)\n",
    "                    print(\"%d,%d -> %f\" % (i,j,v))\n",
    "                    print(\"%d,%d -> %f\" % (i,j,state[i][j]))\n",
    "                    self.u0.Print()\n",
    "                k += 1\n",
    "        self.state = state\n",
    "        return state\n",
    "        \n",
    "    # In RLlib, you need the config arg\n",
    "    def __init__(self,config):\n",
    "        self.meshfile = 'inline-quad-5.mesh'\n",
    "        self.mesh = mfem.Mesh(self.meshfile)\n",
    "        \n",
    "        # The only reason we need to create a fespace and gf here\n",
    "        # is to find the sizes needed for the action and observation spaces\n",
    "        dim = self.mesh.Dimension()\n",
    "        self.order = 1\n",
    "        self.fec = mfem.L2_FECollection(self.order, dim)\n",
    "        self.fes = mfem.FiniteElementSpace(self.mesh, self.fec)\n",
    "        self.u = mfem.GridFunction(self.fes);\n",
    "\n",
    "        # actions are: do nothing (0) or refine center element (1)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        \n",
    "        self.obsx = 42\n",
    "        self.obsy = 42\n",
    "        \n",
    "        # observation space: 42x42 image\n",
    "        self.observation_space = spaces.Box(-1.0, 2.0, shape=(self.obsx,self.obsy,1))\n",
    "\n",
    "    def step(self, action):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to load a trained policy, and apply it in a strided way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:16:03,121\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.201',\n",
       " 'raylet_ip_address': '192.168.1.201',\n",
       " 'redis_address': '192.168.1.201:35154',\n",
       " 'object_store_address': '/tmp/ray/session_2021-02-26_21-16-02_494368_5464/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-02-26_21-16-02_494368_5464/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8267',\n",
       " 'session_dir': '/tmp/ray/session_2021-02-26_21-16-02_494368_5464',\n",
       " 'metrics_export_port': 63789,\n",
       " 'node_id': '50123b4473b6fcf8b984d6084d70eed04d0d64144c8233325c967135'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m 2021-02-26 22:00:45,739\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m 2021-02-26 22:00:45,739\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m 2021-02-26 22:00:45,739\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=6763)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2021-02-26 22:00:49,026\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-02-26 22:00:59,655\tINFO trainable.py:103 -- Trainable.setup took 19.702 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-02-26 22:00:59,656\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_workers': 3,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 200,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 1000,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': False,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'num_framestacks': 'auto',\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1,\n",
       "  'framestack': True},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {},\n",
       " 'env': None,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 5e-05,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': True,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent',\n",
       "  'count_steps_by': 'env_steps'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 30,\n",
       " 'lr_schedule': None,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'simple_optimizer': False,\n",
       " '_fake_gpus': False,\n",
       " 'vf_share_layers': -1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_config = ppo.DEFAULT_CONFIG.copy()\n",
    "dqn_config = dqn.DEFAULT_CONFIG.copy()\n",
    "\n",
    "#ppo_config['framework'] = 'tfe'\n",
    "#dqn_config['num_workers'] = 1\n",
    "\n",
    "ppo_config['train_batch_size'] = 1000\n",
    "ppo_config['num_workers'] = 3\n",
    "ppo_config['num_gpus'] = 0\n",
    "\n",
    "agent = ppo.PPOTrainer(ppo_config, env=EstimatorGameDummy)\n",
    "\n",
    "#agent = dqn.DQNTrainer(dqn_config, env=AMRGameDummy)\n",
    "ppo_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore a policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 22:01:00,314\tINFO trainable.py:372 -- Restored on 192.168.1.201 from checkpoint: /home/rwa/ray_results/PPO_EstimatorGame_2021-02-26_20-55-36iny1vi4_/checkpoint_5/checkpoint-5\n",
      "2021-02-26 22:01:00,315\tINFO trainable.py:379 -- Current state after restoring: {'_iteration': 5, '_timesteps_total': None, '_time_total': 468.9241576194763, '_episodes_total': 6000}\n"
     ]
    }
   ],
   "source": [
    "agent.restore(\"/home/rwa/ray_results/PPO_EstimatorGame_2021-02-26_20-55-36iny1vi4_/checkpoint_5/checkpoint-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m 2021-02-26 22:01:08,346\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m 2021-02-26 22:01:08,346\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m 2021-02-26 22:01:08,346\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m 2021-02-26 22:01:08,359\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m 2021-02-26 22:01:08,359\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m 2021-02-26 22:01:08,359\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27087)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m WARNING:tensorflow:From /home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27086)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "policy = agent.get_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create the larger problem we'll be applying this local indicator on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    }
   ],
   "source": [
    "mesh = mfem.Mesh('inline-quad-30.mesh')\n",
    "print(mesh.GetNE())\n",
    "fec = mfem.L2_FECollection(p=1, dim=2)\n",
    "fes = mfem.FiniteElementSpace(mesh, fec)\n",
    "u = mfem.GridFunction(fes)\n",
    "u0 = mfem.GridFunction(fes)\n",
    "coeff = Bump()\n",
    "coeff.SetParams()\n",
    "u.ProjectCoefficient(coeff)\n",
    "u0.Assign(u) # save so we can restore later if desired\n",
    "    \n",
    "def new_function():\n",
    "    global mesh, fec, fes, u, u0, coeff\n",
    "    mesh = mfem.Mesh('inline-quad-30.mesh')\n",
    "    fec = mfem.L2_FECollection(p=1, dim=2)\n",
    "    fes = mfem.FiniteElementSpace(mesh, fec)\n",
    "    u = mfem.GridFunction(fes)\n",
    "    u0 = mfem.GridFunction(fes)\n",
    "    coeff = Bump()\n",
    "    coeff.SetParams()\n",
    "    u.ProjectCoefficient(coeff)\n",
    "    u0.Assign(u) # save so we can restore later if desired\n",
    "    return glvis(to_stream(mesh,u) + 'keys Rcjm', 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_function():\n",
    "    global mesh, fec, fes, u\n",
    "    mesh = mfem.Mesh('inline-quad-30.mesh')\n",
    "    fec = mfem.L2_FECollection(p=1, dim=2)\n",
    "    fes = mfem.FiniteElementSpace(mesh, fec)\n",
    "    u = mfem.GridFunction(fes)\n",
    "    u.Assign(u0)\n",
    "    #return glvis(to_stream(mesh,u) + 'keys Rcjm', 500, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a map from each element to the elements which consist of the \"stencil\" around it. Since not every element has a full stencil, use a dictionary that only contains the elements containing full stencils as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stencils(mesh, width):\n",
    "    els = {}\n",
    "    nx = math.sqrt(mesh.GetNE())\n",
    "    dx = 1.0/nx\n",
    "    dim = mesh.Dimension()\n",
    "    els = {}\n",
    "    hw = int(width/2)\n",
    "    c = mfem.Vector(dim)\n",
    "    x = mfem.Vector(dim)\n",
    "    for k in range(0,mesh.GetNE()):\n",
    "        els[k] = []\n",
    "        mesh.GetElementCenter(k,c)\n",
    "        full = True\n",
    "        for j in range(-hw,hw+1):\n",
    "            for i in range(-hw,hw+1):\n",
    "                x[0] = c[0]+i*dx\n",
    "                x[1] = c[1]+j*dx\n",
    "                if (x[0] < 0.0): full = False\n",
    "                if (x[0] > 1.0): full = False\n",
    "                if (x[1] < 0.0): full = False\n",
    "                if (x[1] > 1.0): full = False\n",
    "                pt = [[x[0],x[1]]]\n",
    "                n, el, ip = mesh.FindPoints(pt)\n",
    "                els[k].append(el[0])\n",
    "        if (not full):\n",
    "            els.pop(k)\n",
    "    return els"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function and build the stencils for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_function()\n",
    "width=5\n",
    "els = build_stencils(mesh, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the local observation mesh into which we will copy the dofs for the purposes of creating an observation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0f60dd30b14023b67b45ac40892348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "glvis(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_mesh = mfem.Mesh('inline-quad-5.mesh')\n",
    "obs_fec = mfem.L2_FECollection(p=1, dim=2)\n",
    "obs_fes = mfem.FiniteElementSpace(obs_mesh, obs_fec)\n",
    "obs_u = mfem.GridFunction(obs_fes)\n",
    "glvis((obs_mesh), 400, 400,layout = Layout(width='100%', height='400px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also build a 0th order L2 field to look at per-element quantities (like logits or prob dist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec0 = mfem.L2_FECollection(p=0, dim=2)\n",
    "fes0 = mfem.FiniteElementSpace(obs_mesh, fec0)\n",
    "obs_u0 = mfem.GridFunction(fes0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a mapping from the \"logical\" space of the observation mesh into element ids. This has the same ordering as the stencil elements, so we can form a mapping for the purposes of data transfer from the src mesh to the obs mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map(obs_mesh, width):\n",
    "    id_map = []\n",
    "    c = [0.5, 0.5]\n",
    "    x = [0.0, 0.0]\n",
    "    dx = 1./width\n",
    "    hw = int(width/2)\n",
    "    for j in range(-hw,hw+1):\n",
    "        for i in range(-hw,hw+1):\n",
    "            x[0] = c[0]+i*dx\n",
    "            x[1] = c[1]+j*dx\n",
    "            pt = [[x[0],x[1]]]\n",
    "            n, el, ip = obs_mesh.FindPoints(pt)\n",
    "            id_map.append(el[0])\n",
    "    return id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = build_map(obs_mesh, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to transfer from the stencil associated with a src element k into the observation gf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_stencil(k):\n",
    "    global obs_u\n",
    "    for n in range(len(els[k])):\n",
    "        dst_el = id_map[n]\n",
    "        src_el = els[k][n]\n",
    "        #print(\"el %d -> el %d\" % (src_el,dst_el))\n",
    "        src_dofs = fes.GetElementDofs(src_el)\n",
    "        dst_dofs = obs_fes.GetElementDofs(dst_el)\n",
    "        for d in range(len(src_dofs)):\n",
    "            obs_u[dst_dofs[d]] = u[src_dofs[d]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the observation mesh and function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_obs():\n",
    "    return glvis(to_stream(obs_mesh,obs_u) + 'keys Rcjm', 500, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the logits for each element in the observation mesh and visualize as a p=0 L2 function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_patch_logits():\n",
    "    obs = np.array(obs_u.GetDataArray())\n",
    "    action, _, info = policy.compute_single_action(obs, explore=False)\n",
    "    logits = np.array(info['action_dist_inputs'],dtype=np.float64)\n",
    "    obs_u0.Assign(mfem.Vector(logits))\n",
    "    return glvis(to_stream(obs_mesh,obs_u0) + 'keys Rcjm', 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_patch_qvalues():\n",
    "    obs = np.array(obs_u.GetDataArray())\n",
    "    action, _, info = policy.compute_single_action(obs, explore=False)\n",
    "    print(info)\n",
    "    qvalues = np.array(info['q_values'],dtype=np.float64)\n",
    "    obs_u0.Assign(mfem.Vector(qvalues))\n",
    "    return glvis(to_stream(obs_mesh,obs_u0) + 'keys Rcjm', 500, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out on a specific src element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50432d7760d4979a668ec52af5338d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "glvis()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transfer_stencil(10)\n",
    "show_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_patch_logits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show_patch_qvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transfer_stencil(889)\n",
    "show_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_patch_logits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all the elements with full stencils in the src mesh and record 'center' logits for each observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = [[0.5,0.5]]\n",
    "n, center_el, ip = obs_mesh.FindPoints(pt)\n",
    "center_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_center_logits(mesh):\n",
    "    logits = [-1.0]*mesh.GetNE()\n",
    "    for k in els:\n",
    "        transfer_stencil(k)\n",
    "        obs = np.array(obs_u.GetDataArray())\n",
    "        action, _, info = policy.compute_single_action(obs, explore=False)\n",
    "        obs_logits = info['q_values']\n",
    "        #value = info['vf_preds']\n",
    "        #print(\"value is %f\" % value)\n",
    "        \n",
    "        # find minimum to use as datum\n",
    "        #min_logit = 1.e6\n",
    "        #for j in range(len(id_map)):\n",
    "        #    src_el = id_map[j]\n",
    "        #    min_logit = min(min_logit,obs_logits[src_el])\n",
    "        \n",
    "        logits[k] = obs_logits[center_el][0] # -min_logit\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_actions(mesh):\n",
    "    actions = [0.0]*mesh.GetNE()\n",
    "    for k in els:\n",
    "        transfer_stencil(k)\n",
    "        obs = env.get_obs()\n",
    "        actions[k], _, info = policy.compute_single_action(obs, explore=False)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9c98f110484046844bb3b149c8e169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "glvis()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:17:47,360\tERROR tf_run_builder.py:47 -- Error fetching: [<tf.Tensor 'default_policy/cond_1/Merge:0' shape=(?,) dtype=int64>, {'action_prob': <tf.Tensor 'default_policy/Exp:0' shape=(?,) dtype=float32>, 'action_logp': <tf.Tensor 'default_policy/cond_2/Merge:0' shape=(?,) dtype=float32>, 'action_dist_inputs': <tf.Tensor 'default_policy/Squeeze:0' shape=(?, 2) dtype=float32>, 'vf_preds': <tf.Tensor 'default_policy/Reshape_1:0' shape=(?,) dtype=float32>}], feed_dict={<tf.Tensor 'default_policy/obs:0' shape=(?, 42, 42, 1) dtype=float32>: [array([5.43666893e-62, 2.84434875e-60, 1.09953042e-60, 5.75250769e-59,\n",
      "       4.86857089e-59, 2.18028851e-57, 9.84636341e-58, 4.40948966e-56,\n",
      "       8.40469204e-57, 3.76386704e-55, 1.45498554e-55, 6.51585101e-54,\n",
      "       9.38540879e-60, 4.91024489e-58, 1.62476317e-58, 8.50041295e-57,\n",
      "       1.23764228e-57, 6.47507934e-56, 1.83397967e-56, 9.59498888e-55,\n",
      "       1.24669068e-55, 6.52241865e-54, 1.58132306e-54, 8.27314360e-53,\n",
      "       9.59276764e-54, 5.01873060e-52, 1.04152171e-52, 5.44901853e-51,\n",
      "       8.59038319e-51, 3.84702497e-49, 9.32689177e-50, 4.17685506e-48,\n",
      "       1.11641927e-52, 4.99965219e-51, 1.41608465e-51, 6.34164145e-50,\n",
      "       1.10831637e-54, 4.96336502e-53, 1.64234022e-53, 7.35488009e-52,\n",
      "       7.58148000e-52, 2.90622324e-50, 1.12344903e-50, 4.30653869e-49,\n",
      "       7.63690821e-50, 2.92747064e-48, 9.68678057e-49, 3.71325214e-47,\n",
      "       5.87628409e-48, 2.25256723e-46, 6.38009557e-47, 2.44569425e-45,\n",
      "       3.07053934e-45, 1.00751647e-43, 3.33379635e-44, 1.09389731e-42,\n",
      "       1.22559839e-42, 3.44229574e-41, 1.33067679e-41, 3.73742581e-40,\n",
      "       1.59280632e-44, 4.47365992e-43, 2.02034186e-43, 5.67446417e-42,\n",
      "       3.99051964e-47, 1.30938373e-45, 5.06164106e-46, 1.66084396e-44,\n",
      "       3.96155670e-49, 1.29988030e-47, 5.87036706e-48, 1.92620606e-46,\n",
      "       1.58124583e-46, 4.44119038e-45, 2.34314290e-45, 6.58110427e-44,\n",
      "       1.19910565e-48, 3.36788651e-47, 2.07584214e-47, 5.83034589e-46,\n",
      "       3.00416605e-51, 9.85737824e-50, 5.20068807e-50, 1.70646857e-48,\n",
      "       5.74926136e-54, 2.20387536e-52, 9.95288357e-53, 3.81525791e-51,\n",
      "       3.33036432e-56, 1.27663493e-54, 6.73544211e-55, 2.58190992e-53,\n",
      "       1.74021788e-53, 5.71006582e-52, 3.51947585e-52, 1.15482314e-50,\n",
      "       6.94603783e-51, 1.95090958e-49, 1.40479032e-49, 3.94558591e-48])], <tf.Tensor 'default_policy/is_training:0' shape=() dtype=bool>: False, <tf.Tensor 'default_policy/is_exploring:0' shape=() dtype=bool>: False, <tf.Tensor 'default_policy/timestep:0' shape=() dtype=int64>: 0}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\", line 44, in get\n",
      "    self.feed_dict, os.environ.get(\"TF_TIMELINE_DIR\"))\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n",
      "    fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1156, in _run\n",
      "    (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n",
      "ValueError: Cannot feed value of shape (1, 100) for Tensor 'default_policy/obs:0', which has shape '(?, 42, 42, 1)'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 100) for Tensor 'default_policy/obs:0', which has shape '(?, 42, 42, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-33921edaaaeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_center_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-c32f2c793e2f>\u001b[0m in \u001b[0;36mget_center_actions\u001b[0;34m(mesh)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtransfer_stencil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_single_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/policy/policy.py\u001b[0m in \u001b[0;36mcompute_single_action\u001b[0;34m(self, obs, state, prev_action, prev_reward, info, episode, clip_actions, explore, timestep, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mexplore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             timestep=timestep)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Some policies don't return a tuple, but always just a single action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py\u001b[0m in \u001b[0;36mcompute_actions\u001b[0;34m(self, obs_batch, state_batches, prev_action_batch, prev_reward_batch, info_batch, episodes, explore, timestep, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;31m# Execute session run to get action (and other fetches).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_fetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;31m# Update our global timestep by the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, to_fetch)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 logger.exception(\"Error fetching: {}, feed_dict={}\".format(\n\u001b[1;32m     47\u001b[0m                     self.fetches, self.feed_dict))\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_fetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_fetch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, to_fetch)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 self._executed = run_timeline(\n\u001b[1;32m     43\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     self.feed_dict, os.environ.get(\"TF_TIMELINE_DIR\"))\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 logger.exception(\"Error fetching: {}, feed_dict={}\".format(\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\u001b[0m in \u001b[0;36mrun_timeline\u001b[0;34m(sess, ops, debug_name, feed_dict, timeline_dir)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;34m\"Executing TF run without tracing. To dump TF timeline traces \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \"to disk, set the TF_TIMELINE_DIR environment variable.\")\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 100) for Tensor 'default_policy/obs:0', which has shape '(?, 42, 42, 1)'"
     ]
    }
   ],
   "source": [
    "actions = get_center_actions(mesh)\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-26 21:17:14,637\tERROR tf_run_builder.py:47 -- Error fetching: [<tf.Tensor 'default_policy/cond_1/Merge:0' shape=(?,) dtype=int64>, {'action_prob': <tf.Tensor 'default_policy/Exp:0' shape=(?,) dtype=float32>, 'action_logp': <tf.Tensor 'default_policy/cond_2/Merge:0' shape=(?,) dtype=float32>, 'action_dist_inputs': <tf.Tensor 'default_policy/Squeeze:0' shape=(?, 2) dtype=float32>, 'vf_preds': <tf.Tensor 'default_policy/Reshape_1:0' shape=(?,) dtype=float32>}], feed_dict={<tf.Tensor 'default_policy/obs:0' shape=(?, 42, 42, 1) dtype=float32>: [array([5.43666893e-62, 2.84434875e-60, 1.09953042e-60, 5.75250769e-59,\n",
      "       4.86857089e-59, 2.18028851e-57, 9.84636341e-58, 4.40948966e-56,\n",
      "       8.40469204e-57, 3.76386704e-55, 1.45498554e-55, 6.51585101e-54,\n",
      "       9.38540879e-60, 4.91024489e-58, 1.62476317e-58, 8.50041295e-57,\n",
      "       1.23764228e-57, 6.47507934e-56, 1.83397967e-56, 9.59498888e-55,\n",
      "       1.24669068e-55, 6.52241865e-54, 1.58132306e-54, 8.27314360e-53,\n",
      "       9.59276764e-54, 5.01873060e-52, 1.04152171e-52, 5.44901853e-51,\n",
      "       8.59038319e-51, 3.84702497e-49, 9.32689177e-50, 4.17685506e-48,\n",
      "       1.11641927e-52, 4.99965219e-51, 1.41608465e-51, 6.34164145e-50,\n",
      "       1.10831637e-54, 4.96336502e-53, 1.64234022e-53, 7.35488009e-52,\n",
      "       7.58148000e-52, 2.90622324e-50, 1.12344903e-50, 4.30653869e-49,\n",
      "       7.63690821e-50, 2.92747064e-48, 9.68678057e-49, 3.71325214e-47,\n",
      "       5.87628409e-48, 2.25256723e-46, 6.38009557e-47, 2.44569425e-45,\n",
      "       3.07053934e-45, 1.00751647e-43, 3.33379635e-44, 1.09389731e-42,\n",
      "       1.22559839e-42, 3.44229574e-41, 1.33067679e-41, 3.73742581e-40,\n",
      "       1.59280632e-44, 4.47365992e-43, 2.02034186e-43, 5.67446417e-42,\n",
      "       3.99051964e-47, 1.30938373e-45, 5.06164106e-46, 1.66084396e-44,\n",
      "       3.96155670e-49, 1.29988030e-47, 5.87036706e-48, 1.92620606e-46,\n",
      "       1.58124583e-46, 4.44119038e-45, 2.34314290e-45, 6.58110427e-44,\n",
      "       1.19910565e-48, 3.36788651e-47, 2.07584214e-47, 5.83034589e-46,\n",
      "       3.00416605e-51, 9.85737824e-50, 5.20068807e-50, 1.70646857e-48,\n",
      "       5.74926136e-54, 2.20387536e-52, 9.95288357e-53, 3.81525791e-51,\n",
      "       3.33036432e-56, 1.27663493e-54, 6.73544211e-55, 2.58190992e-53,\n",
      "       1.74021788e-53, 5.71006582e-52, 3.51947585e-52, 1.15482314e-50,\n",
      "       6.94603783e-51, 1.95090958e-49, 1.40479032e-49, 3.94558591e-48])], <tf.Tensor 'default_policy/is_training:0' shape=() dtype=bool>: False, <tf.Tensor 'default_policy/is_exploring:0' shape=() dtype=bool>: False, <tf.Tensor 'default_policy/timestep:0' shape=() dtype=int64>: 0}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\", line 44, in get\n",
      "    self.feed_dict, os.environ.get(\"TF_TIMELINE_DIR\"))\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\", line 89, in run_timeline\n",
      "    fetches = sess.run(ops, feed_dict=feed_dict)\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/rwa/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1156, in _run\n",
      "    (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n",
      "ValueError: Cannot feed value of shape (1, 100) for Tensor 'default_policy/obs:0', which has shape '(?, 42, 42, 1)'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 100) for Tensor 'default_policy/obs:0', which has shape '(?, 42, 42, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ba07593f0aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_center_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfec0fm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL2_FECollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfes0fm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFiniteElementSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfec0fm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlog_fm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfes0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog_fm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-c32f2c793e2f>\u001b[0m in \u001b[0;36mget_center_actions\u001b[0;34m(mesh)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtransfer_stencil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_single_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/policy/policy.py\u001b[0m in \u001b[0;36mcompute_single_action\u001b[0;34m(self, obs, state, prev_action, prev_reward, info, episode, clip_actions, explore, timestep, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mexplore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             timestep=timestep)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Some policies don't return a tuple, but always just a single action.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py\u001b[0m in \u001b[0;36mcompute_actions\u001b[0;34m(self, obs_batch, state_batches, prev_action_batch, prev_reward_batch, info_batch, episodes, explore, timestep, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;31m# Execute session run to get action (and other fetches).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_fetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;31m# Update our global timestep by the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, to_fetch)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 logger.exception(\"Error fetching: {}, feed_dict={}\".format(\n\u001b[1;32m     47\u001b[0m                     self.fetches, self.feed_dict))\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_fetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_fetch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, to_fetch)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 self._executed = run_timeline(\n\u001b[1;32m     43\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     self.feed_dict, os.environ.get(\"TF_TIMELINE_DIR\"))\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 logger.exception(\"Error fetching: {}, feed_dict={}\".format(\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/ray/rllib/utils/tf_run_builder.py\u001b[0m in \u001b[0;36mrun_timeline\u001b[0;34m(sess, ops, debug_name, feed_dict, timeline_dir)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;34m\"Executing TF run without tracing. To dump TF timeline traces \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \"to disk, set the TF_TIMELINE_DIR environment variable.\")\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/minigame_tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 100) for Tensor 'default_policy/obs:0', which has shape '(?, 42, 42, 1)'"
     ]
    }
   ],
   "source": [
    "fec0fm = mfem.L2_FECollection(p=0, dim=2)\n",
    "fes0fm = mfem.FiniteElementSpace(mesh, fec0fm)\n",
    "log_fm = mfem.GridFunction(fes0)\n",
    "log_fm.Assign(mfem.Vector(np.array(actions)))\n",
    "glvis(to_stream(mesh, log_fm), 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_logits(mesh):\n",
    "    logits = [0.0]*mesh.GetNE()\n",
    "    count = [0]*mesh.GetNE()\n",
    "    \n",
    "    # accumulate logit sums\n",
    "    for k in els:\n",
    "        print (\"el %d\" % k)\n",
    "        transfer_stencil(k)\n",
    "        obs = np.array(obs_u.GetDataArray())\n",
    "        action, _, info = policy.compute_single_action(obs, explore=False)\n",
    "        obs_logits = info['q_values']\n",
    "        \n",
    "        # find minimum to use as datum\n",
    "#        min_logit = 1.e6\n",
    "#        for j in range(len(id_map)):\n",
    "#            src_el = id_map[j]\n",
    "#            min_logit = min(min_logit,obs_logits[src_el])\n",
    "\n",
    "        for j in range(len(id_map)):\n",
    "            dst_el = els[k][j]\n",
    "            src_el = id_map[j]\n",
    "            logits[dst_el] += obs_logits[src_el] #-min_logit\n",
    "            count[dst_el] += 1\n",
    "    \n",
    "    # average\n",
    "    for idx,val in enumerate(logits):\n",
    "        logits[idx] /= count[idx]\n",
    "        if (count[idx] < 16):\n",
    "            logits[idx] = -10\n",
    "        #logits[idx] /= obs_mesh.GetNE()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = compute_avg_logits(mesh)\n",
    "fec0fm = mfem.L2_FECollection(p=0, dim=2)\n",
    "fes0fm = mfem.FiniteElementSpace(mesh, fec0fm)\n",
    "log_fm = mfem.GridFunction(fes0)\n",
    "log_fm.Assign(mfem.Vector(np.array(logits)))\n",
    "glvis(to_stream(mesh, log_fm), 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_logits(mesh):\n",
    "    logits = [100.]*mesh.GetNE()\n",
    "    \n",
    "    # choose the max at each element\n",
    "    for k in els:\n",
    "        transfer_stencil(k)\n",
    "        obs = np.array(obs_u.GetDataArray())\n",
    "        action, _, info = policy.compute_single_action(obs, explore=False)\n",
    "        #print(\"action is %d\" % action)\n",
    "        obs_logits = info['action_dist_inputs']\n",
    "        #print(obs_logits)\n",
    "        for j in range(len(id_map)):\n",
    "            dst_el = els[k][j]\n",
    "            src_el = id_map[j]\n",
    "            logits[dst_el] = min(logits[dst_el],obs_logits[src_el])\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_max_q(mesh):\n",
    "    logits = [-100.]*mesh.GetNE()\n",
    "    \n",
    "    # choose the max *in each patch*\n",
    "    for k in els:\n",
    "        transfer_stencil(k)\n",
    "        obs = np.array(obs_u.GetDataArray())\n",
    "        action, _, info = policy.compute_single_action(obs, explore=False)\n",
    "        #print(\"action is %d\" % action)\n",
    "        obs_logits = info['q_values']\n",
    "        #print(obs_logits)\n",
    "        maxq = -1.e6\n",
    "        for j in range(len(id_map)):\n",
    "            dst_el = els[k][j]\n",
    "            src_el = id_map[j]\n",
    "            q = obs_logits[src_el]\n",
    "            if (q > maxq):\n",
    "                maxq = q\n",
    "                src = src_el\n",
    "                dst = dst_el\n",
    "        logits[dst] = obs_logits[src_el]\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-normalize the collected logits into a probability distribution that sums to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_distribution(mesh, u, method):\n",
    "    if (method == 1):\n",
    "        logits = compute_center_logits(mesh)\n",
    "    elif (method == 2):\n",
    "        logits = compute_avg_logits(mesh)\n",
    "    elif (method == 3):\n",
    "        logits = compute_min_logits(mesh)\n",
    "    elif (method == 4):\n",
    "        logits = compose_max_q(mesh)\n",
    "    sumexp = 0.0\n",
    "    dist = [0.0] * mesh.GetNE()\n",
    "    for k in range(mesh.GetNE()):        \n",
    "        logit = logits[k]\n",
    "        sumexp += math.exp(logit)\n",
    "    for k in range(mesh.GetNE()):\n",
    "        logit = logits[k]\n",
    "        dist[k] = math.exp(logit)/sumexp\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a similar function that returns elementwise errors via the dg indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dg_indicator(mesh, u):\n",
    "    \n",
    "    # put the L2 gridfunction into a coefficient so we can project it into H1\n",
    "    u_disc_coeff = mfem.GridFunctionCoefficient(u)\n",
    "    h1_fec = mfem.H1_FECollection(p=1, dim=2)\n",
    "    h1_fes = mfem.FiniteElementSpace(mesh, h1_fec)\n",
    "    u_h1 = mfem.GridFunction(h1_fes)\n",
    "    u_h1.ProjectDiscCoefficient(u_disc_coeff, mfem.GridFunction.ARITHMETIC)\n",
    "    \n",
    "    # put the H1 smoothed function into a coefficient\n",
    "    u_h1_coeff = mfem.GridFunctionCoefficient(u_h1)\n",
    "    \n",
    "    # create a 0-order L2 field to hold errors\n",
    "    l2_0_fec = mfem.L2_FECollection(p=0,dim=2)\n",
    "    l2_0_fes = mfem.FiniteElementSpace(mesh,l2_0_fec)\n",
    "\n",
    "    # Compute elementwise \"errors\" between continuous and discontinuous fields\n",
    "    err_gf = mfem.GridFunction(l2_0_fes);\n",
    "    u.ComputeElementL2Errors(u_h1_coeff, err_gf);\n",
    "    \n",
    "    return np.array(err_gf.GetDataArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_actual_error_reduction(mesh, u, u0):\n",
    "    init_err = u.ComputeL2Error(coeff)\n",
    "    print(\"init_err: %f\" % init_err)\n",
    "    delta_elem_err = []\n",
    "    for k in range(mesh.GetNE()):\n",
    "        mesh = mfem.Mesh('inline-quad-30.mesh')\n",
    "        fec = mfem.L2_FECollection(p=1, dim=2)\n",
    "        fes = mfem.FiniteElementSpace(mesh, fec)\n",
    "        u = mfem.GridFunction(fes)\n",
    "        u.Assign(u0)\n",
    "    \n",
    "        refine_els = []\n",
    "        refine_els.append(k)\n",
    "        mesh.GeneralRefinement(mfem.intArray(refine_els))\n",
    "        u.FESpace().Update()\n",
    "        u.Update()\n",
    "        u.ProjectCoefficient(coeff)\n",
    "        new_err = u.ComputeL2Error(coeff)\n",
    "        #print(\"delta for %d is %e\" % (k,init_err-new_err))\n",
    "        delta_elem_err.append(init_err -new_err)\n",
    "\n",
    "    return delta_elem_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an indicator on each element, refine everything over the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_via_indicator(ind, mesh, u, thresh):\n",
    "    refine_els = []\n",
    "    for k,e in enumerate(ind):\n",
    "        if (e > thresh):\n",
    "            refine_els.append(k)\n",
    "    mesh.GeneralRefinement(mfem.intArray(refine_els))\n",
    "    u.FESpace().Update()\n",
    "    u.Update()\n",
    "    return glvis(to_stream(mesh,u) + 'keys Rcjm', 500, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine everywhere the policy is over a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_via_policy_threshold(mesh, u, thresh, method):\n",
    "    dist = compute_distribution(mesh, u, method)\n",
    "    return refine_via_indicator(dist, mesh, u, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine everywhere the DG indicator is over a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_via_dg_threshold(mesh, u, thresh):\n",
    "    ind = compute_dg_indicator(mesh, u)\n",
    "    return refine_via_indicator(ind, mesh, u, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_topk_via_indicator(ind, mesh, u, K):\n",
    "    refine_els = []\n",
    "    indsort = np.argsort(ind)[::-1]\n",
    "    for i in range(K):\n",
    "        refine_els.append(indsort[i])\n",
    "    mesh.GeneralRefinement(mfem.intArray(refine_els))\n",
    "    u.FESpace().Update()\n",
    "    u.Update()\n",
    "    return glvis(to_stream(mesh,u) + 'keys Rjm', 400, 400,layout = Layout(width='100%', height='400px'))\n",
    " \n",
    "def refine_topk_via_policy(mesh, u, K, method):\n",
    "    dist = compute_distribution(mesh, u, method)\n",
    "    return refine_topk_via_indicator(dist, mesh, u, K)\n",
    " \n",
    "def refine_topk_via_dg(mesh, u, K):\n",
    "    ind = compute_dg_indicator(mesh, u)\n",
    "    return refine_topk_via_indicator(ind, mesh, u, K)\n",
    "\n",
    "def refine_topk_via_delta_elem_err(mesh, u, K):\n",
    "    return refine_topk_via_indicator(delta_elem_err, mesh, u, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_elem_err = compute_actual_error_reduction(mesh, u, u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_function()\n",
    "refine_topk_via_delta_elem_err(mesh, u, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "restore_function()\n",
    "refine_topk_via_dg(mesh, u, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_function()\n",
    "method = 1 # center\n",
    "refine_topk_via_policy(mesh, u, 100, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restore_function()\n",
    "method = 2 # avg\n",
    "refine_topk_via_policy(mesh, u, 100, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_function()\n",
    "method = 4 # max q\n",
    "refine_topk_via_policy(mesh, u, 100, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_function()\n",
    "refine_topk_via_dg(mesh, u, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_function()\n",
    "method = 1 # center\n",
    "refine_topk_via_policy(mesh, u, 100, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_function()\n",
    "method = 2 # avg\n",
    "refine_topk_via_policy(mesh, u, 100, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minigame_tf1",
   "language": "python",
   "name": "minigame_tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
