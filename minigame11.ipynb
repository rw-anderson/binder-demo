{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minigame 11: Choose One Element To Refine And Advect Mesh\n",
    "\n",
    "Experiment: try a 50/50 chance of advecting one element left or one element right, with the direction as part of the observation. variation: try twice as frequent NN updates (50k vs 100k per batch), to see if it learns faster.\n",
    "\n",
    "This is like minigame10, except that we're now \"advecting\" the field by displacing the mesh. This is like a remap method, where the remap is just to re-project the known function onto the new mesh.\n",
    "\n",
    "In this context, we want to refine not where our finest features are right now, but where they will be after the advection. In this sense, the policy has a way to do \"anticipatory\" refinement, which is a new strategic consideration for the policy. The DG indicator doesn't take this into account, so the policy at least in principle may be able to get ahead here.\n",
    "\n",
    "In a typical AMR code, this is usually accounted for by \"buffering\" refined areas, so that refined features do not leave a refined zone before the next regrid phase. This buffering is ad-hoc and doesn't usually take into account, for example, the local direction of advection.\n",
    "\n",
    "Setup PyMFEM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import cos,sin\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "from gym import spaces, utils\n",
    "import numpy as np\n",
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyglvis import GlvisWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mfem import path\n",
    "import mfem.ser as mfem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a utility function for using pyglvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solnstream(mesh,soln):\n",
    "    mesh.Print(\",tmpmesh\")\n",
    "    with open(\",tmpmesh\",\"r\") as f:\n",
    "        meshdata = f.read()\n",
    "    soln.Save(\",tmpsoln\")\n",
    "    with open(\",tmpsoln\",\"r\") as f:\n",
    "        solndata = f.read()\n",
    "    solndata = \"solution\\n\"+meshdata+solndata\n",
    "    return solndata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some synthetic test functions: steps and bumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(x,theta):\n",
    "    x0 = x[0]\n",
    "    y0 = x[1]\n",
    "    x1 = x0*cos(theta)-y0*sin(theta)\n",
    "    y1 = x0*sin(theta)+y0*cos(theta)\n",
    "    return [x1,y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    x0 = x[0]\n",
    "    if (x0 < 0.0):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotated_step(x, theta):\n",
    "    xr = rotate(x,theta)\n",
    "    return step(xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bump(x):\n",
    "    rsq = x[0]**2 +x[1]**2\n",
    "    return math.exp(-rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_step(x):\n",
    "    return 0.5*(1.0 +math.tanh(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotated_smooth_step(x,theta):\n",
    "    xr = rotate(x,theta)\n",
    "    return smooth_step(xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create classes where we can set the parameters and then eval a bunch of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.theta = random.uniform(0.0, 2.0*math.pi)\n",
    "        self.dx = [random.uniform(-1.0, 1.0),random.uniform(-1.0, 1.0)]\n",
    "        \n",
    "    def EvalValue(self, x):\n",
    "        return rotated_step(x+self.dx, self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bump(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.width = random.uniform(0.1,1.0)\n",
    "        self.xc = [0.5,0.5]\n",
    "        self.dx = [random.uniform(-0.5, 0.5),random.uniform(-0.5, 0.5)]\n",
    "\n",
    "    def EvalValue(self, x):\n",
    "        return bump((x-self.xc+self.dx)/self.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoBump(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.width1 = random.uniform(0.1,0.5)\n",
    "        self.width2 = random.uniform(0.1,0.5)\n",
    "        self.xc1 = [0.5,0.5]\n",
    "        self.xc2 = [0.5,0.5]\n",
    "        self.dx1 = [random.uniform(-0.5, 0.5),random.uniform(-0.5, 0.5)]\n",
    "        self.dx2 = [random.uniform(-0.5, 0.5),random.uniform(-0.5, 0.5)]\n",
    "\n",
    "    def EvalValue(self, x):\n",
    "        #return max(bump((x-self.xc1+self.dx1)/self.width1),bump((x-self.xc2+self.dx2)/self.width2))\n",
    "        return 0.5*(bump((x-self.xc1+self.dx1)/self.width1)+bump((x-self.xc2+self.dx2)/self.width2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothStep(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.width = random.uniform(5.0, 10.0)\n",
    "        self.xc = [0.5,0.5]\n",
    "        self.theta = random.uniform(0.0, 2.0*math.pi)\n",
    "\n",
    "    def EvalValue(self, x):\n",
    "        x -= self.xc\n",
    "        return rotated_smooth_step(x*self.width, self.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BumpsAndSmoothStep(mfem.PyCoefficient):\n",
    "    \n",
    "    def SetParams(self):\n",
    "        self.bump = Bump()\n",
    "        self.bump.SetParams()\n",
    "        self.smooth_step = SmoothStep()\n",
    "        self.smooth_step.SetParams()\n",
    "\n",
    "    def EvalValue(self, x):\n",
    "        return 0.5*self.bump.EvalValue(x)+0.5*self.smooth_step.EvalValue(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize an instance of the test function. Note that each instance has randomly chosen parameters.  For the steps, it's a rotation angle and a displacement.  For the bumps, it's a width and a displacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = mfem.Mesh('inline-quad.mesh')\n",
    "mesh.UniformRefinement()\n",
    "mesh.UniformRefinement()\n",
    "mesh.UniformRefinement()\n",
    "fec = mfem.L2_FECollection(p=1, dim=2)\n",
    "fes = mfem.FiniteElementSpace(mesh, fec)\n",
    "u = mfem.GridFunction(fes)\n",
    "c = BumpsAndSmoothStep()\n",
    "c.SetParams()\n",
    "u.ProjectCoefficient(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0790a2c82004bdc81dfd8112a0d9937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gl = GlvisWidget(get_solnstream(mesh,u))\n",
    "gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRGame(gym.Env):\n",
    "    \n",
    "    class u0_coeff(mfem.PyCoefficient):\n",
    "        \n",
    "        def SetParams(self):\n",
    "            self.fn = BumpsAndSmoothStep()\n",
    "            self.fn.SetParams()\n",
    "            \n",
    "        def EvalValue(self, x):\n",
    "            return self.fn.EvalValue(x)\n",
    "    \n",
    "    def set_displ(self):\n",
    "        self.ud = random.uniform(-1.0, 1.0)\n",
    "        self.vd = random.uniform(-1.0, 1.0)\n",
    "        \n",
    "        # tmp - simpler velocity model\n",
    "        self.ud = 0.0\n",
    "        self.vd = 0.0\n",
    "        alpha = random.uniform(0.0, 1.0)\n",
    "        if (alpha > 0.5):\n",
    "            self.ud = 1.0\n",
    "        else:\n",
    "            self.ud = -1.0\n",
    "\n",
    "        mag = math.sqrt(self.ud**2 +self.vd**2)\n",
    "        nx = math.sqrt(self.mesh.GetNE())\n",
    "        self.ud /= mag\n",
    "        self.ud /= nx\n",
    "        self.vd /= mag\n",
    "        self.vd /= nx\n",
    "            \n",
    "        nv = self.mesh.GetNV()\n",
    "        uda = np.full((nv),self.ud)\n",
    "        vda = np.full((nv),self.vd)\n",
    "        uvda = np.concatenate((uda,vda))\n",
    "        self.displ = mfem.Vector(nv*2)\n",
    "        self.displ.Assign(uvda)\n",
    "        \n",
    "    # In RLlib, you need the config arg\n",
    "    def __init__(self,config):\n",
    "        self.meshfile = 'inline-quad-7.mesh'\n",
    "        \n",
    "        # keep a copy of the unrefined mesh so we can restore it\n",
    "        self.mesh0 = mfem.Mesh(self.meshfile)\n",
    "        self.mesh = mfem.Mesh(self.meshfile)\n",
    "        \n",
    "        # The only reason we need to create a fespace and gf here\n",
    "        # is to find the sizes needed for the action and observation spaces\n",
    "        dim = self.mesh.Dimension()\n",
    "        self.order = 1\n",
    "        self.fec = mfem.L2_FECollection(self.order, dim)\n",
    "        self.fes = mfem.FiniteElementSpace(self.mesh, self.fec)\n",
    "        self.u = mfem.GridFunction(self.fes);\n",
    "\n",
    "        # actions are: refine each element, or do nothing\n",
    "        self.action_space = spaces.Discrete(self.mesh.GetNE())\n",
    "        \n",
    "        # observation space: DOFs plus two velocity components\n",
    "        self.observation_space = spaces.Box(-1.0, 1.0, shape=(self.u.Size()+2,), dtype=np.float32)\n",
    "        \n",
    "        # call reset to create the first synthetic function\n",
    "        self.reset()\n",
    "                \n",
    "    def get_ne(self):\n",
    "        return self.mesh.GetNE()\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.u.Size()\n",
    "    \n",
    "    # Compute L2 error wrt to the analytic fn definition\n",
    "    def get_error(self):\n",
    "        err = self.u.ComputeL2Error(self.u0)\n",
    "        return err\n",
    "    \n",
    "    # Manually refine the elements, then update and re-project\n",
    "    def refine_elems(self, elems):\n",
    "        self.mesh.GeneralRefinement(mfem.intArray(elems))\n",
    "        self.fes.Update()\n",
    "        self.u.Update()\n",
    "        self.u.ProjectCoefficient(self.u0)\n",
    "        \n",
    "    # action is the number of the element to refine\n",
    "    def step(self, action):\n",
    "        err1 = self.get_error()\n",
    "        self.mesh.MoveVertices(self.displ)\n",
    "        self.refine_elems([action])\n",
    "        \n",
    "        err2 = self.get_error()\n",
    "        reward = err1-err2\n",
    "        done = True\n",
    "        \n",
    "        obs = self.u.GetDataArray()\n",
    "        obs = np.append(obs,[self.ud, self.vd])\n",
    "        return np.array(obs), reward, done, {}\n",
    "    \n",
    "    # similar to reset, but do not choose a new function\n",
    "    def reinit(self):\n",
    "        del self.mesh\n",
    "        self.mesh = mfem.Mesh(self.mesh0)\n",
    "\n",
    "        del self.fes\n",
    "        self.fes = mfem.FiniteElementSpace(self.mesh, self.fec)\n",
    "\n",
    "        del self.u\n",
    "        self.u = mfem.GridFunction(self.fes)\n",
    "        self.u.ProjectCoefficient(self.u0)\n",
    "        \n",
    "        obs = self.u.GetDataArray()\n",
    "        obs = np.append(obs,[self.ud, self.vd])\n",
    "        return np.array(obs)\n",
    "    \n",
    "    # every reset of the env chooses a new synthetic function\n",
    "    def reset(self):\n",
    "        self.u0 = self.u0_coeff()\n",
    "        \n",
    "        # set the random function parameters\n",
    "        self.u0.SetParams()\n",
    "        \n",
    "        # set the random mesh displacement\n",
    "        self.set_displ()\n",
    "        \n",
    "        return self.reinit()\n",
    "    \n",
    "    def render(self):\n",
    "        return GlvisWidget(get_solnstream(self.mesh,self.u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the environment and sanity check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AMRGame(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AMRGame(None)\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9f16265b6b483a8bfa4fb192140a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state, reward, done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b34c197b7174e2285b492b37434c2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show with refinement of element 0. Then we'll test resetting it to the original state.  We're going to need this to go through a searching for the best actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8e1a6762fb4a428795e87c9e15aa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reinit()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, try training a policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 12:27:46,235\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_workers': 3,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 200,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 10000,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {},\n",
       " 'env': None,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 5e-05,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tfe',\n",
       " 'eager_tracing': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': True,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 30,\n",
       " 'lr_schedule': None,\n",
       " 'vf_share_layers': False,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'simple_optimizer': False,\n",
       " '_fake_gpus': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "# This env setting is necessary to avoid problems within rllib due to serialization and workers\n",
    "ray.init(ignore_reinit_error=True)\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config['train_batch_size'] = int(1e4)\n",
    "config['num_workers'] = 3\n",
    "config['framework'] = 'tfe'\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 12:27:48,911\tINFO trainer.py:588 -- Executing eagerly, with eager_tracing=False\n",
      "2021-02-15 12:27:48,912\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m non-resource variables are not supported in the long term\n",
      "2021-02-15 12:27:52,170\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config['train_batch_size'] = int(1e3)\n",
    "agent = ppo.PPOTrainer(config, env=AMRGame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m 2021-02-15 12:27:52,183\tWARNING deprecation.py:30 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/evaluation/collectors/simple_list_collector.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m   arr = np.array(v)\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/evaluation/collectors/simple_list_collector.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m   arr = np.array(v)\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/evaluation/collectors/simple_list_collector.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m   arr = np.array(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:852: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "episode reward mean: -0.000127 \n",
      "CPU times: user 7.55 s, sys: 222 ms, total: 7.78 s\n",
      "Wall time: 17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:852: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1846)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:852: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1849)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:852: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1848)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in range(1):\n",
    "    result = agent.train()\n",
    "    print(\"episode reward mean: %f \" % result[\"episode_reward_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observations (InputLayer)       [(None, 198)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fc_1 (Dense)                    (None, 256)          50944       observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_1 (Dense)              (None, 256)          50944       observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Dense)                    (None, 256)          65792       fc_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_2 (Dense)              (None, 256)          65792       fc_value_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc_out (Dense)                  (None, 49)           12593       fc_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "value_out (Dense)               (None, 1)            257         fc_value_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 246,322\n",
      "Trainable params: 246,322\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "policy = agent.get_policy()\n",
    "model = policy.model\n",
    "print(model.base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a convenience function for applying a policy to a given observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_policy(model, obs):\n",
    "    action = agent.compute_action(obs, explore=False) # use deterministic mode\n",
    "    state, reward, done, info = env.step(action)\n",
    "    #print(\"policy chooses action %d with reward %f\" % (action, reward))\n",
    "    return action, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed45661a612452d834ab12be782ff7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64383051ef4a4988bf2a5a84c538a0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "action, reward = apply_policy(model, obs)\n",
    "action, reward\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 2.385590343672965e-06)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reinit()\n",
    "action, reward = apply_policy(model, obs)\n",
    "action, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bfc46fdd15404d8fba33642ba7f664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brute force search for the best choice by trying each one, remembering to reset the environment after each action and after we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_optimal(obs):\n",
    "    u0 = mfem.Vector(obs)\n",
    "    maxr = 0.0;\n",
    "    maxel = -1;\n",
    "    env.reinit()\n",
    "    ne = env.get_ne()\n",
    "    for n in range(ne):\n",
    "        env.reinit()\n",
    "        state, reward, done, info = env.step(n)\n",
    "        if reward > maxr:\n",
    "            maxr = reward\n",
    "            maxel = n\n",
    "    #print(\"max reward is %f by refining element %d\" % (maxr, maxel))\n",
    "    env.reinit()\n",
    "    return maxel, maxr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2faa1a2a52ea4f3a8e9b296bbd1d5c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs = env.reinit()\n",
    "maxel, maxr = find_optimal(obs)\n",
    "env.step(maxel)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with what the policy does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f82650ea3e44a199eb16793f04972e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reinit()\n",
    "apply_policy(model,obs)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an error estimator based on the difference between the discontinuous and continuous representations. This is only valid for L2 FE spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dgjumps(env):\n",
    "    \n",
    "    mesh = env.mesh\n",
    "    u = env.u\n",
    "    \n",
    "    # put the L2 gridfunction into a coefficient so we can project it\n",
    "    u_disc_coeff = mfem.GridFunctionCoefficient(u)\n",
    "    h1_fec = mfem.H1_FECollection(p=1, dim=2)\n",
    "    h1_fes = mfem.FiniteElementSpace(mesh, h1_fec)\n",
    "    u_h1 = mfem.GridFunction(h1_fes)\n",
    "    u_h1.ProjectDiscCoefficient(u_disc_coeff, mfem.GridFunction.ARITHMETIC)\n",
    "    \n",
    "    # put the H1 smoothed function into a coefficient\n",
    "    u_h1_coeff = mfem.GridFunctionCoefficient(u_h1)\n",
    "    \n",
    "    # create a 0-order L2 field to hold errors\n",
    "    l2_0_fec = mfem.L2_FECollection(p=0,dim=2)\n",
    "    l2_0_fes = mfem.FiniteElementSpace(mesh,l2_0_fec)\n",
    "\n",
    "    # Compute elementwise \"errors\" between continuous and discontinuous fields\n",
    "    err_gf = mfem.GridFunction(l2_0_fes);\n",
    "    u.ComputeElementL2Errors(u_h1_coeff, err_gf);\n",
    "    \n",
    "    best_action = np.argmax(err_gf.GetDataArray())\n",
    "    \n",
    "    state, reward, done, info = env.step(best_action)\n",
    "    env.reinit()\n",
    "\n",
    "    return best_action, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d77151e5044d396166ae7792cd7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GlvisWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reinit()\n",
    "action, reward = find_dgjumps(env)\n",
    "env.step(action)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random policy gives us a scale for the low end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_policy(obs):\n",
    "    ne = env.get_ne()\n",
    "    ir = np.random.randint(0,ne)\n",
    "    state, reward, done, info = env.step(ir)\n",
    "    env.reinit()\n",
    "    return ir, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a more systematic evaluation using an ensemble of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ensemble(model, ntrials):\n",
    "    \n",
    "    ncorrect = 0\n",
    "    sumsq = 0.0\n",
    "    maxerrsq = 0.0\n",
    "    \n",
    "    dg_ncorrect = 0\n",
    "    dg_sumsq = 0.0\n",
    "    dg_maxerrsq = 0.0\n",
    "    \n",
    "    rand_ncorrect = 0\n",
    "    rand_sumsq = 0.0\n",
    "    rand_maxerrsq = 0.0\n",
    "    for n in range(ntrials):\n",
    "        obs = env.reset()\n",
    "        \n",
    "        bestaction, bestreward = find_optimal(obs) # this reinits\n",
    "        dgaction, dgreward = find_dgjumps(env)     # this reinits\n",
    "        action, reward = apply_policy(model,obs)   # this doesn't reinit\n",
    "        env.reinit()\n",
    "        rand_action, rand_reward = apply_random_policy(obs)\n",
    "        \n",
    "        err = bestreward-reward\n",
    "        maxerrsq = max(err**2,maxerrsq)\n",
    "        sumsq += err**2\n",
    "        \n",
    "        dg_err = bestreward-dgreward\n",
    "        dg_maxerrsq = max(dg_err**2,dg_maxerrsq)\n",
    "        dg_sumsq += dg_err**2\n",
    "        \n",
    "        rand_err = bestreward-rand_reward\n",
    "        rand_maxerrsq = max(rand_err**2,rand_maxerrsq)\n",
    "        rand_sumsq += rand_err**2\n",
    "        \n",
    "        if (bestaction == action):\n",
    "            ncorrect += 1\n",
    "        if (bestaction == dgaction):\n",
    "            dg_ncorrect += 1\n",
    "        if (bestaction == rand_action):\n",
    "            rand_ncorrect += 1\n",
    "    \n",
    "    rms = math.sqrt(sumsq/ntrials)\n",
    "    corr = 100.*ncorrect/ntrials\n",
    "    print(\"policy rms error: \",rms,flush=True)\n",
    "    print(\"policy max sq error: \",math.sqrt(maxerrsq),flush=True)\n",
    "    print(\"policy % correct: \",corr,flush=True)\n",
    "    \n",
    "    dg_rms = math.sqrt(dg_sumsq/ntrials)\n",
    "    dg_corr = 100.*dg_ncorrect/ntrials\n",
    "    print(\"dg rms error: \",dg_rms,flush=True)\n",
    "    print(\"dg max sq error: \",math.sqrt(dg_maxerrsq),flush=True)\n",
    "    print(\"dg % correct: \",dg_corr,flush=True)\n",
    "    \n",
    "    rand_rms = math.sqrt(rand_sumsq/ntrials)\n",
    "    rand_corr = 100.*rand_ncorrect/ntrials\n",
    "    print(\"rand rms error: \",rand_rms,flush=True)\n",
    "    print(\"rand max sq error: \",math.sqrt(rand_maxerrsq),flush=True)\n",
    "    print(\"rand % correct: \",rand_corr,flush=True)\n",
    "    \n",
    "    return rms, math.sqrt(maxerrsq), corr, dg_rms, math.sqrt(dg_maxerrsq), dg_corr, rand_rms, math.sqrt(rand_maxerrsq), rand_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "eval_ensemble(model, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a few eval sample sizes to get a sense of how many are needed to estimate the metrics of the policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval_ensemble(model, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval_ensemble(model, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the training process is making progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_phase(nbatches, neval):\n",
    "    start_batches = len(rms)\n",
    "    for n in range(nbatches):\n",
    "        done_batches = len(rms)\n",
    "        print(\"training batch %d/%d (%d episodes)\" % (done_batches,start_batches+nbatches,batch_size))\n",
    "        agent.train()\n",
    "        agent.save()\n",
    "        print(\"evaluating on %d instances...\" %  neval)\n",
    "        rms0, maxerr0, cor0, dg_rms0, dg_maxerr0, dg_cor0, rand_rms0, rand_maxerr0, rand_cor0 = eval_ensemble(model, neval)\n",
    "        rms.append(rms0)\n",
    "        maxerr.append(maxerr0)\n",
    "        cor.append(cor0)\n",
    "        dg_rms.append(dg_rms0)\n",
    "        dg_maxerr.append(dg_maxerr0)\n",
    "        dg_cor.append(dg_cor0)\n",
    "        rand_rms.append(rand_rms0)\n",
    "        rand_maxerr.append(rand_maxerr0)\n",
    "        rand_cor.append(rand_cor0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m non-resource variables are not supported in the long term\n",
      "2021-02-15 12:28:13,233\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "phase_episodes = 5.e5\n",
    "nbatches = 10\n",
    "batch_size = phase_episodes/nbatches\n",
    "neval = 400\n",
    "\n",
    "del agent\n",
    "config['train_batch_size'] = int(batch_size)\n",
    "agent = ppo.PPOTrainer(config, env=AMRGame)\n",
    "policy = agent.get_policy()\n",
    "model = policy.model\n",
    "\n",
    "rms = []\n",
    "maxerr = []\n",
    "cor = []\n",
    "dg_rms = []\n",
    "dg_maxerr = []\n",
    "dg_cor = []\n",
    "rand_rms = []\n",
    "rand_maxerr = []\n",
    "rand_cor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 0/10 (50000 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m 2021-02-15 12:28:16,312\tWARNING deprecation.py:30 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/evaluation/collectors/simple_list_collector.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m   arr = np.array(v)\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/evaluation/collectors/simple_list_collector.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m   arr = np.array(v)\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/evaluation/collectors/simple_list_collector.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m   arr = np.array(v)\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:852: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1847)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:852: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2281)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m WARNING:tensorflow:From /home/rwa/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:852: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=2280)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005160900048243777\n",
      "policy max sq error:  0.004362262725727607\n",
      "policy % correct:  2.0\n",
      "dg rms error:  0.00043654840303800307\n",
      "dg max sq error:  0.003772822781266871\n",
      "dg % correct:  4.0\n",
      "rand rms error:  0.0005248079155827307\n",
      "rand max sq error:  0.003897459578620666\n",
      "rand % correct:  3.0\n",
      "training batch 1/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0004692910139587568\n",
      "policy max sq error:  0.003705776907139644\n",
      "policy % correct:  4.0\n",
      "dg rms error:  0.0003580984375402149\n",
      "dg max sq error:  0.0031052983936051565\n",
      "dg % correct:  5.25\n",
      "rand rms error:  0.0004915446048075715\n",
      "rand max sq error:  0.0036973880742775557\n",
      "rand % correct:  1.5\n",
      "training batch 2/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005052453155885746\n",
      "policy max sq error:  0.0035030913292938316\n",
      "policy % correct:  4.5\n",
      "dg rms error:  0.00042656715509569056\n",
      "dg max sq error:  0.003061968190320898\n",
      "dg % correct:  7.5\n",
      "rand rms error:  0.0005173219844251075\n",
      "rand max sq error:  0.003484087050944171\n",
      "rand % correct:  3.5\n",
      "training batch 3/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0004855296513937192\n",
      "policy max sq error:  0.003266312204775023\n",
      "policy % correct:  5.25\n",
      "dg rms error:  0.00043875208247653313\n",
      "dg max sq error:  0.0029977943764255433\n",
      "dg % correct:  5.75\n",
      "rand rms error:  0.0005628002324781383\n",
      "rand max sq error:  0.0034726567819961477\n",
      "rand % correct:  1.5\n",
      "training batch 4/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005288125132375903\n",
      "policy max sq error:  0.003793479608235912\n",
      "policy % correct:  5.25\n",
      "dg rms error:  0.00043984052581484614\n",
      "dg max sq error:  0.003169715951512211\n",
      "dg % correct:  7.25\n",
      "rand rms error:  0.0005403631702552751\n",
      "rand max sq error:  0.0038873030709254443\n",
      "rand % correct:  2.0\n",
      "training batch 5/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005783536643636439\n",
      "policy max sq error:  0.0031397176996110533\n",
      "policy % correct:  4.5\n",
      "dg rms error:  0.0004877389689153882\n",
      "dg max sq error:  0.002849333216489754\n",
      "dg % correct:  5.25\n",
      "rand rms error:  0.0005939653283380107\n",
      "rand max sq error:  0.0031726609817698103\n",
      "rand % correct:  2.0\n",
      "training batch 6/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005255850366031598\n",
      "policy max sq error:  0.003282207703297197\n",
      "policy % correct:  8.0\n",
      "dg rms error:  0.0004653103647259859\n",
      "dg max sq error:  0.0028620718548578086\n",
      "dg % correct:  8.0\n",
      "rand rms error:  0.0005738198896435169\n",
      "rand max sq error:  0.0032434990688346363\n",
      "rand % correct:  1.5\n",
      "training batch 7/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005595370254842573\n",
      "policy max sq error:  0.004071373008178259\n",
      "policy % correct:  7.0\n",
      "dg rms error:  0.00048662553747674044\n",
      "dg max sq error:  0.0037786514925816726\n",
      "dg % correct:  4.75\n",
      "rand rms error:  0.0006026024284256614\n",
      "rand max sq error:  0.004100693197703574\n",
      "rand % correct:  1.75\n",
      "training batch 8/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005186413815602554\n",
      "policy max sq error:  0.0038438117944925177\n",
      "policy % correct:  8.0\n",
      "dg rms error:  0.00043950662963752646\n",
      "dg max sq error:  0.00309708717180115\n",
      "dg % correct:  5.75\n",
      "rand rms error:  0.0005580287014462479\n",
      "rand max sq error:  0.0038634747632078793\n",
      "rand % correct:  1.75\n",
      "training batch 9/10 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005067369420289514\n",
      "policy max sq error:  0.004398023881339384\n",
      "policy % correct:  10.25\n",
      "dg rms error:  0.0004868227269751384\n",
      "dg max sq error:  0.003552706485493679\n",
      "dg % correct:  5.25\n",
      "rand rms error:  0.0005742582870823462\n",
      "rand max sq error:  0.004428998949813653\n",
      "rand % correct:  2.5\n"
     ]
    }
   ],
   "source": [
    "train_phase(nbatches, neval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plotprogress():\n",
    "    isteps = list(range(len(rms)))\n",
    "    asteps = [(i+1)*config['train_batch_size'] for i in isteps]\n",
    "    ax = plt.subplot(211)\n",
    "    #ax.set_ylim(0.0001,0.01)\n",
    "    ax.set_ylabel('Loss')\n",
    "    line1, = plt.semilogy(asteps,rms, marker='o')\n",
    "    line2, = plt.semilogy(asteps,dg_rms, marker='x')\n",
    "    line3, = plt.semilogy(asteps,rand_rms)\n",
    "\n",
    "    line4, = plt.semilogy(asteps,maxerr, marker='.')\n",
    "    line5, = plt.semilogy(asteps,dg_maxerr, marker='+')\n",
    "    line6, = plt.semilogy(asteps,rand_maxerr)\n",
    "\n",
    "    line1.set_label('RL rms')\n",
    "    line2.set_label('DG rms')\n",
    "    line3.set_label('RNG rms')\n",
    "    line4.set_label('RL max')\n",
    "    line5.set_label('DG max')\n",
    "    line6.set_label('RNG max')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "\n",
    "    ax = plt.subplot(212)\n",
    "    ax.set_ylim(1,100)\n",
    "    ax.set_ylabel('% correct')\n",
    "    ax.set_xlabel('training episodes')\n",
    "    line1, = plt.semilogy(asteps,cor, marker='o')\n",
    "    line2, = plt.semilogy(asteps,dg_cor, marker='x')\n",
    "    line3, = plt.semilogy(asteps,rand_cor)\n",
    "\n",
    "    line1.set_label('RL')\n",
    "    line2.set_label('DG')\n",
    "    line3.set_label('RNG')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotprogress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch 10/20 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0003501310816831751\n",
      "policy max sq error:  0.002096809439386665\n",
      "policy % correct:  8.75\n",
      "dg rms error:  0.00028069867778511147\n",
      "dg max sq error:  0.0017288008528696481\n",
      "dg % correct:  4.5\n",
      "rand rms error:  0.00038343576979253777\n",
      "rand max sq error:  0.002090462240113537\n",
      "rand % correct:  1.0\n",
      "training batch 11/20 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005272671634483743\n",
      "policy max sq error:  0.0032042966214426687\n",
      "policy % correct:  9.75\n",
      "dg rms error:  0.00045151079925415257\n",
      "dg max sq error:  0.0028416055548199787\n",
      "dg % correct:  5.75\n",
      "rand rms error:  0.000546156581260422\n",
      "rand max sq error:  0.00322281066855906\n",
      "rand % correct:  1.25\n",
      "training batch 12/20 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005567589859496226\n",
      "policy max sq error:  0.0049105794582421924\n",
      "policy % correct:  10.0\n",
      "dg rms error:  0.0004897726386745556\n",
      "dg max sq error:  0.00455213466302014\n",
      "dg % correct:  8.5\n",
      "rand rms error:  0.0005936665819548547\n",
      "rand max sq error:  0.00491900500171613\n",
      "rand % correct:  1.5\n",
      "training batch 13/20 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005385331249379642\n",
      "policy max sq error:  0.00355269530957275\n",
      "policy % correct:  9.0\n",
      "dg rms error:  0.0005011650716481736\n",
      "dg max sq error:  0.0031787806687390077\n",
      "dg % correct:  4.75\n",
      "rand rms error:  0.0006182443716202186\n",
      "rand max sq error:  0.004086150042541446\n",
      "rand % correct:  1.75\n",
      "training batch 14/20 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005178819617495013\n",
      "policy max sq error:  0.004852943401925542\n",
      "policy % correct:  13.75\n",
      "dg rms error:  0.0005048311961816642\n",
      "dg max sq error:  0.004134836683480509\n",
      "dg % correct:  5.25\n",
      "rand rms error:  0.000619960090899\n",
      "rand max sq error:  0.004852943401925542\n",
      "rand % correct:  2.0\n",
      "training batch 15/20 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0005039510208963377\n",
      "policy max sq error:  0.0033150934950987847\n",
      "policy % correct:  16.0\n",
      "dg rms error:  0.0004809846554421559\n",
      "dg max sq error:  0.0029422879517042207\n",
      "dg % correct:  5.75\n",
      "rand rms error:  0.0005824652975784157\n",
      "rand max sq error:  0.003441028001933865\n",
      "rand % correct:  2.5\n",
      "training batch 16/20 (50000 episodes)\n",
      "evaluating on 400 instances...\n",
      "policy rms error:  0.0004562488732109261\n",
      "policy max sq error:  0.0036408512304973812\n",
      "policy % correct:  14.75\n",
      "dg rms error:  0.00042130332760956474\n",
      "dg max sq error:  0.003812095279652002\n",
      "dg % correct:  7.25\n",
      "rand rms error:  0.0005275057795998381\n",
      "rand max sq error:  0.004180642703671374\n",
      "rand % correct:  2.0\n",
      "training batch 17/20 (50000 episodes)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-81530a30c1b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-105519861b2c>\u001b[0m in \u001b[0;36mtrain_phase\u001b[0;34m(nbatches, neval)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdone_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training batch %d/%d (%d episodes)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdone_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_batches\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnbatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluating on %d instances...\"\u001b[0m \u001b[0;34m%\u001b[0m  \u001b[0mneval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMAX_WORKER_FAILURE_RETRIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRayError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ignore_worker_failures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[1;32m    182\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"step() needs to return a dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    789\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m                             \u001b[0;32myield\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/execution/train_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     batch, {p: w.get_policy(p)\n\u001b[1;32m     64\u001b[0m                             for p in self.policies}, w, self.num_sgd_iter,\n\u001b[0;32m---> 65\u001b[0;31m                     self.sgd_minibatch_size, [])\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# TODO(ekl) shouldn't be returning learner stats directly here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLEARNER_INFO\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/utils/sgd.py\u001b[0m in \u001b[0;36mdo_minibatch_sgd\u001b[0;34m(samples, policies, local_worker, num_sgd_iter, sgd_minibatch_size, standardize_fields)\u001b[0m\n\u001b[1;32m    129\u001b[0m                     MultiAgentBatch({\n\u001b[1;32m    130\u001b[0m                         \u001b[0mpolicy_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                     }, minibatch.count)))[policy_id]\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_fetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLEARNER_STATS_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0miter_extra_fetches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\u001b[0m in \u001b[0;36mlearn_on_batch\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    825\u001b[0m                         builder, batch)\n\u001b[1;32m    826\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m                     \u001b[0minfo_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0minfo_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_fetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/eager_tf_policy.py\u001b[0m in \u001b[0;36mlearn_on_batch\u001b[0;34m(self, postprocessed_batch)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_seq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 batch_divisibility_req=self.batch_divisibility_req)\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learn_on_batch_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpostprocessed_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mconvert_eager_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/eager_tf_policy.py\u001b[0m in \u001b[0;36m_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"info_batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"episodes\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             }\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/eager_tf_policy.py\u001b[0m in \u001b[0;36m_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_to_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/eager_tf_policy.py\u001b[0m in \u001b[0;36m_learn_on_batch_eager\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_learn_on_batch_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_disallow_var_creation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/policy/eager_tf_policy.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 model_out, _ = self.model(samples, self._state_in,\n\u001b[0;32m--> 604\u001b[0;31m                                           samples.get(\"seq_lens\"))\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/models/modelv2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mrestored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs_flat\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         if ((not isinstance(res, list) and not isinstance(res, tuple))\n\u001b[1;32m    211\u001b[0m                 or len(res) != 2):\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/ray/rllib/models/tf/fcnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 seq_lens: TensorType) -> (TensorType, List[TensorType]):\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mmodel_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs_flat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_supports_masking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_mask_metadata\u001b[0;34m(self, inputs, outputs, previous_mask, build_graph)\u001b[0m\n\u001b[1;32m   2529\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m     mask_already_computed = (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_phase(nbatches, neval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotprogress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phase(nbatches, neval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotprogress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phase(nbatches, neval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotprogress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for cases where the policy gets it right and the DG method gets it wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for n in range(500):\n",
    "    obs = env.reset()\n",
    "    opt_action, opt_reward = find_optimal(obs)\n",
    "    dg_action, dg_reward = find_dgjumps(env)\n",
    "    pol_action, pol_reward = apply_policy(model, obs)\n",
    "    if ((pol_action == opt_action) and (dg_action != opt_action)):\n",
    "        break\n",
    "env.reinit()\n",
    "env.step(pol_action)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env.reinit()\n",
    "env.step(dg_action)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phase(nbatches, neval)\n",
    "plotprogress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minigame",
   "language": "python",
   "name": "minigame"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
